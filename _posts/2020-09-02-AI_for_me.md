---
layout: post
title:  "ML & me"
date:   2020-04-24 22:21:49 +1000
categories: ML
permalink: /:title.html
---

# 序言

这篇文章Version 1更新于我做机器学习研究的第一年，课题是应用于HVAC系统故障检测：说实在，导师原来的课题大概是想做predictive maintenance，但他们比较‘开放’，所以当因为数据原因，我提出更改课题时也就这么改了，后来我索性连数据都换了。不过这次开放性的研究经历大大提高了我对机器学习实际应用的审题能力和对数据质量与label重要性有个深刻的感知。

另外，我本科并不是数学或计算机专业出生。虽然我本人并不认为这会影响我在相关领域的研究，但是不可避免地因此很多专业上的解释会有欠斟酌，所以在此还是做些背景介绍。我本科学的是旅游和酒店管理，直接相关的课程确实很少，大学本科我只有一门统计学课，从商科的角度更多关注是做survey，sampling等比较实践性的东西。有趣的是，像分布，概率这些东西似乎在这个课上并没涉及太多。不过我另外选修的心理测量课上倒是用过不少。无论如何，不论从工程角度还是数学相关的理论角度，我本科的学习并没有带给我有关工程和理论上的任何直接知识。举例来说，平均数对于我来说也许就是数字相加除以个数而已（而不能联想到期望值，权重，bias等概念）；概率分布只是用来算事件的概率的工具（而不能自然地认知到它是总体/事物本质在概率上的表达，sampling process，通过样本可以进行其参数估计等）。

接着，在2017年，因为在滴滴工作时对编程实现一些自动化的报表觉得很有意思，再加上，那会因为大数据的热潮带动了很多相关网课的出现，由此给我自学编程与机器学习提供了极大的方便。所以，便‘入坑了’。而且到澳洲来读了个IT的硕士学位（因为澳洲不受本科的限制）。



# 为什么数据科学与机器学习会火？

在2012年后深度学习提高了人工智能任务的准确性后，学者们逐渐意识到数据尤其是大数据的应用价值。这才催动了‘数据’作为一个科学学科的代名词。然而，从本质上看，科学是解释世界的理论，如果真的对任何的事物都能用一个数学公式来解释它的静态/动态（各维度）的过程，那么数据只是这些过程中产生出来的样本。所以本质上研究数据其实是一种反向推导的过程（英文叫inductive）。比如下面小学经常遇到的推断题：2，4，6，8，___, 12，下划线部分应该是多少？如果你是已知产生这些数字的公式：y=2x，那么这是deductive method。但是数据科学，是用已知的数据（2，4，6，8，12）来推导这个公式然后计算出下划线的数据或者直接根据猜想+2规律得到10，这个推断的过程就是数据科学所研究的，或者说是inductive methods。因为数据量大，多是用计算机编程实现的，在计算机科学领域，这些inductive methods叫做算法，为了区别于传统的计算机算法，更流行的说法是机器学习算法。

所以虽然数据科学领域数据的收集/存储/处理时很重要。但是这篇文章主要讲机器学习。**如果把数据比喻成客观世界，模型比喻成一个对客观世界有所认知的大脑，那么机器学习是孕育大脑的母体。**



# 什么是机器学习？

当然，机器学习的算法只是一种应用工具，对于数据工程师来说也许对其原理并不感兴趣。但是无论是作为一名算法工程师还是对抽象事物充满好奇心的任何人，了解机器学习的原理是非常有意思的一件事。这一是这篇文章的主要篇幅所在。

简单来说，机器学习作为句子来讲的话其实是缺乏宾语的。填补完整：机器学习统计模型。还可以加上定语：机器从数据从学习统计模型。如此一来，一个构建机器学习任务所需要的东西就显而易见了。

1. 统计模型：统计学是基于样本研究可generalized到总体的模型表示。所以其实在用计算机学习模型参数之前，统计模型依然是可以由人工根据统计方式（e.g. MLE, MAP）计算训练出来。
2. 如何“学习”统计模型？：学习的过程其实就是利用优化方法来计算训练模型参数使得模型能做正确的判断（弱AI的概念来源于此）。类比人脑的话，优化提供了让大脑快速成长的催化剂，当然这个好的催化剂不仅催化的快，而且方向正确（能催化成天才，否则就会成傻瓜）。
3. 如何表示数据？：线性代数提供了数据表示的方式，这里表示的不仅是描述客观世界的信息，还有模型参数的表示。之所以用这种表示不仅是利用矩阵运算的效率（可以并行运算），其实还有很多其它的好处。比如：1.联系方程到几何空间上：在深度神经网络中，本质在每一层对这一层的输入进行矩阵变换，W就是变换矩阵。可以从几何空间上形象的想象，输入X为原本的空间上的n个点/向量。W*X是变换后空间上的点/向量。2.利用其性质来构造模型：比如深度神经网络中之所以在每层要激活函数，是因为如果仅仅是线性变换，无论多少线性变换叠加，其结果其实也只是一个线性变换(X1=W1*X0+b1, X2=W2*X1+b2 => X2=W3*X0+b3)。
4. 机器（如何在机器上实现以上的3点？）：这里就需要计算机工程的能力。也就是俗称程序员所需要做的事。

所以所需的专业知识上来讲：***机器学习 = 统计 | Statistics + 线性代数 | Linear Algebra + 优化 | Optimization, Linear Programming +工程 | Computer Engineering***



**为什么机器学习经常会和AI联系在一起？** 

**1.从计算机自动化的角度：计算机本身为实现自动化的任务/应用而生。而每类机器学习算法其实就是一个装着理论的篮子。来自各个数学子领域的理论结合起来从而有效的让计算机基于数据自动化的学习模型参数。从自动化的角度，这听起来就很人工智能AI不是。**

**2.从任务的角度，在这些模型能解决的任务中很多其中很像只有人/生物能做的任务：比如让计算机有眼睛能看，能听懂人的语言，也就是CV和NLP，神经网络（或者说是深度学习，因为它有好多好多层好多好多参数）是目前最火效果也好的一类机器学习算法。**



# 统计与机器学

虽然统计学是提供了理论意义上的支撑，但是在我看来理解这些理论对于应用机器学习建立有用的模型是非常重要的。比如：

大数定律揭示了机器学习模型最终能不能很好的解释预测客观时间取决于样本是否足够大。更详细地说估计出的模型参数是否符合总体的分布。



--------------------------这里一下部分是Version 3 的内容，感觉有些想法还是比较幼稚，有时间会更新--------------------------

- 因为现实世界虽然是有规律但是也具有不确定性，所以机器学习所使用的数据本质就是统计学中的样本。
- 除此之外，很多机器学习模型都是基于统计假设的，比如Naive Bayes 是基于输入特征独立（independence of input variables）的假设。

**PS： 在我上Master课程中机器学习前置课之前，我其实没有意识到统计学对机器学习的理解与应用有多么重要。****例如，像吴恩达课程里那样，从可理解性的角度解释了logistic regression 的loss function(其实从统计的角度是基于二项分布的Log Maximum Likelihood) ，然后编程实现就好（并不是指初学者‘傻瓜式’调包，这掉包的话是你连这个formula的存在都不知道的操作）。当然，这样也许实现上也没问题，甚至有些参数在缺乏统计理论的支持下也是能做的。下面我想说什么你应该知道了，是的，还有些参数是需要从统计角度理解的（最基本却也是很多初学者一个门槛的就是Bias 和Variance）。同样地，如果不能正确的从统计角度理解机器学习模型，很多模型的本质差别很难被发现，这样就算脱离了‘调包侠’，也还是‘模型怪’，不能灵活地更改（甚至微调创造）模型。**

**Tip: 多从公式 | formula的角度去描述模型会有助于理论和实践的结合（至少对大多discriminative model来说模型就是公式，discriminative model下面会说到）。**

其实用时候我经常爱说‘statitstical learning instead of machine learning’，因为把，你想想机器学习的本质就是数据中学习模式（pattern）。但是数据的本质就是样本对总体的描述。所以说statistical learning我觉得没错。那为什么一定要机器学习呢，我想关键在于‘机器’这个字的解释，因为现在这个模型是被机器也就是计算机学习到的，然后在被用于实际的预测场景中，这也解释为什么机器学习这个在上世纪就已经出现的名词为什么现在才火，因为大数据啊，机器的算力提升了。我片面地、从统计的角度来讲，就是统计模型 + 优化算法 + 工程实现，最后出来的东西，就是看似是人工打造的智能学习器。

好啦，下面咱要专业的有深度（我觉得以我之前的水平来说）的说说了。毕竟也是在土澳的无差别研究生课程（速成班）里洗尽铅华来着。其实在研究生课程里统计课（是结合概率论一起学的，作为学习机器学习算法的入门课）上完对于应用在机器学习算法中我其实还是懵逼的，这时候引入的概念多了起来，还和概率论纠缠不清，从基本的随机数，分布到假设检验，置信区间等。当然我抱着最本质的理念来安慰自己：统计就是 用’样本‘推导’总体‘特征。好的，所以在统计科挣扎的伙伴们考试就写这一句老师绝对给你pass。为什么？因为你水平高到就能一句话总结了。别试，只是玩笑：）但分析可以就此开始了。

**本质上，机器学习是指从数据样本中学习从而Estimate’总体‘特征（这个特征可以用多种方式表示，下面会讲），所以需要有统计假设**

再重复遍标题，机器学习模型可以基于**统计假设**用样本数据（历史数据，已有数据，抽样数据）来Esimate总体特征。如果有时间维度的话很可以是forecast未来的结果。而每一个维度样本数据经常被称为特征（feature）大概也是这个原因把（我猜！！！谁知道这个源头，欢迎评论）。

首先要清楚的是机器学习是从数据中学习的，而有限（finite）的数据所能提供的只是总体一部分的信息，而机器学习模型（我每次说到机器学习模型的时候都会在脑海里想象它就是一个数学公式，可能是bayes formula，有可能是algebra formula）。所以说研究机器学习自然少不了统计的理论（这是天生的王八和绿豆----对上眼了）。另外，有统计的地方肯定少不了概率，要个解释的话就是：概率是用来描述总体的一个天生好工具，所以自然而然的，统计用概率分布来通过样本表述总体。

**PS: 统计上，会有假设，假设总体的分布（就是事物的特征，这里区别与机器学习的特征变量，那是multivariate的情况了），比如满足平均值是M的正态分布或者概率是p的伯努利分布。所谓假设，是基于我们对事物的性质的基本判断，例如上海人的身高是符合正态分布，即大多数人都在胡歌的水平线，姚明（太高），那个谁（上海有名的矮个子我还真不知道~）这些属于少数。之所以要假设，是为了利用前人总结出来的规律让我们的问题变简单，例如当假设身高符合正态分布后，我们就可以用正态分布的函数（即概率密度函数）来描述，进一步的，引入样本数据来进行参数估计。**

**参数估计这里要画重点了！！！在这篇post的version 1里我说，“这正是区分传统统计估计和机器学习算法估计的关键。首先传统的方式是用close-formed function，这个也是数学统计领域的专家们多年总结出来的可以直接用来估计参数的方法；另一种机器学习的方法就是使用优化算法来根据数据自动优化的到参数，最常用的莫过于耳熟能详的梯度下降法了。” 其实没差啦，比如简单的linear regression，不管哪种效率高用哪个。**

再进一步，在有监督得机器学习的任务中，变量肯定不止一个（因为除了一个目标变量，你总得有描述变量吧。无监督你可以只有一个变量，那你就直接说你是在玩一元的统计概率分布得了），所以问题其实就变成了multivariate的了。OK。说到这里，其实我觉得已经可以看出本质上他们就是王八和绿豆。下面讲点实际的，统计和概率论对于我们解决机器学习问题，建立机器学习模型，评估机器学习模型到底有什么贡献呢。

**贡献一：建立机器学习模型（统计概率出生的同学要“高潮”了）**

我想对上述的问题，如果是统计出生的同学已经找到一个解决方案了。没错，就是Bayes Theorem。非专业出身的同学也不需要紧张（因为所有高大上理论的都是唬人的，你学不明白是因为你不习惯它的语言），我们可以用人类语言来解释：相比简单的说一个人身高大于1米8的概率是多少，它限定了条件，这个条件也给了你其它信息去提升你估计的准确度（但然前提是这个是相关条件），比如体重60公斤，来自黑龙江的汉子身高大于1米8的概率是多少。OK，如果非统计出身又只想了解些实用的，可以直接跳过下面一段。

Ali Ghodsi课上说，在分类的问题中，理论上，Bayes Classifier能得到最优解（具体的我还没研究，欢迎大家评论区贡献有关文献）。通过Bayes来求得话，我们需要三个东西：Prior, Conditional Class Distribution, Marginal Distribution。但是，在没有足够数据得情况下，Conditional Class Distribution和Marginal Distribution是很难estimate得，尤其是在High dimension。在维基百科关于‘Bayes Classifier’词条里,下面这句话可以借鉴：

**In practice, as in most of statistics, the difficulties and subtleties are associated with modeling the probability distributions effectively—in this case, {\displaystyle \operatorname {P} (Y=r\mid X=x)}. The Bayes classifier is a useful benchmark in [statistical classification](https://en.wikipedia.org/wiki/Statistical_classification).**





**贡献二：统计的方法来Estimate模型的performance**

From the perspective of statistics, it is important to emphasize both the training data and test data are just samples from the population. They can fully represent the population due to the existence of sample bias. But it can be one of ways to estimate the true metrics of the model. For example, normally and naturally, the **sample error** will always be considered to estimate True Error Rate. However, to mitigate the affect of the sample bias, we can use the K-fold cross validation(More: see Reference 3).



# **机器学习和优化算法（Optimization）的关系**

其实机器学习之所以区别于传统的统计模型，关键在于：在提供模型的框架/hypothesis后机器可以自己学习模型的参数。 而参数是通过优化算法学习到的。所以虽然大多时候调用机器学习算法不会太关心具体的优化实现，它在模型的学习效率上（联系到计算机科学中的算法空间和时间复杂度）和最优解上是有差距的。在不考虑训练数据偏差的情况下，这个差距就决定了模型是否实用。（这里具体的针对不同模型框架的优化算法我会后续整理）。





**Generative model vs discriminative model**

再不片面的讲，其实并不一定要用统计的方法来构造总体的行为模型。也就是生成模型（generative model）。很多时候囊括在机器学习算法下构造的模型其实只是在向量空间做了分类，比如SVM，还有聚类（clustering）的模型。



**Statistical model aims for inference while ML resides on the prediction**
“The major difference between machine learning and statistics is their purpose. Machine learning models are designed to make the most accurate predictions possible. Statistical models are designed for inference about the relationships between variables.”

 虽然我现在觉得这个是废话（你statistical model 做完inference不就可以做predict了，又不冲突。但如果你是从目的角度来讲，那真的就是你做这个模型过程会随这目的有些改动。但这个无法具体化，那仍然是废话不是) 但还是有理论的探究意义，也许能对实践有所贡献。就先列在这把(More: see Reference 1)。



# 深度学习

毫无以为，深度学习的突破性应用场景有很多，尤其是在计算机视觉和自然语言处理两块，从人工智能的角度，就是计算机能做一些人眼所能做的任务，能理解人类语言（包括听说读写方方面面）。

未完待续~（To be continued~）

# 机器学习的任务

很多人会 把机器学习和任务一般分为监督学习，半监督学习和无监督学习。有监督的机器学习是最常见的，其目的是得到一个可以做预测做决定（输入-输出）的模型。一般来说，如果是有针对性的，我会说明，否则适用于所用任务的机器学习模型。



# 学习资料

Wikipedia相关词条：一般不了解得概念我会先上wiki看，细节可以以后用到反复琢磨，但是如果整体的意思都理解不了，我会上youtube找可视化效果好，讲解到位的视频，具体的有以下几个号推荐。

Youtube订阅号：3blue1brown, StatQuest

课程： UC Berkeley CS188, MIT6.034, Waterloo STAT 441/841 CM 763: [Statistical Learning Classification](https://uwaterloo.ca/data-analytics/sites/ca.data-analytics/files/uploads/files/f15stat841_outline.pdf)



**Reference**

1. https://towardsdatascience.com/the-actual-difference-between-statistics-and-machine-learning-64b49f07ea3

2. https://en.wikipedia.org/wiki/Statistical_learning_theory

3. http://mlwiki.org/index.php/True_Error_of_Model